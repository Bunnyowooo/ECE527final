{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf88375b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-07 19:30:53.218621: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-12-07 19:30:53.648469: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-12-07 19:30:53.650457: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-07 19:30:54.680641: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow: 2.13.1\n",
      "hls4ml: 0.8.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import hls4ml\n",
    "\n",
    "print(\"TensorFlow:\", tf.__version__)\n",
    "print(\"hls4ml:\", hls4ml.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "742f6966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tiny_autoencoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 784)]             0         \n",
      "                                                                 \n",
      " encoder_dense (Dense)       (None, 32)                25120     \n",
      "                                                                 \n",
      " decoder_dense (Dense)       (None, 784)               25872     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50992 (199.19 KB)\n",
      "Trainable params: 50992 (199.19 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "INPUT_DIM = 784   # 28x28\n",
    "HIDDEN_DIM = 32\n",
    "OUTPUT_DIM = 784\n",
    "LR = 1e-3\n",
    "\n",
    "# Define model\n",
    "inputs = keras.Input(shape=(INPUT_DIM,))\n",
    "\n",
    "# Encoder: 784 -> 32, ReLU\n",
    "encoded = layers.Dense(HIDDEN_DIM, activation='relu', name=\"encoder_dense\")(inputs)\n",
    "\n",
    "# Decoder: 32 -> 784, Sigmoid\n",
    "decoded = layers.Dense(OUTPUT_DIM, activation='sigmoid', name=\"decoder_dense\")(encoded)\n",
    "\n",
    "autoencoder = keras.Model(inputs=inputs, outputs=decoded, name=\"tiny_autoencoder\")\n",
    "\n",
    "autoencoder.summary()\n",
    "\n",
    "# Compile (MSE loss, Adam optimizer)\n",
    "autoencoder.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=LR),\n",
    "    loss='mse'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e91925bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (60000, 784)\n",
      "Test shape: (10000, 784)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-07 19:31:01.147006: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 188160000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-07 19:31:01.512777: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 188160000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "912/938 [============================>.] - ETA: 0s - loss: 0.0421"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-07 19:31:03.881097: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 31360000 exceeds 10% of free system memory.\n",
      "2025-12-07 19:31:03.925165: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 31360000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0416 - val_loss: 0.0225\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0184 - val_loss: 0.0147\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0133 - val_loss: 0.0117\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0114 - val_loss: 0.0106\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0108 - val_loss: 0.0103\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST data\n",
    "(x_train, _), (x_test, _) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalize and flatten to 784-dim vectors\n",
    "x_train = x_train.reshape(-1, 784).astype('float32') / 255.0\n",
    "x_test  = x_test.reshape(-1, 784).astype('float32') / 255.0\n",
    "\n",
    "print(\"Train shape:\", x_train.shape)\n",
    "print(\"Test shape:\", x_test.shape)\n",
    "\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "history = autoencoder.fit(\n",
    "    x_train, x_train,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    validation_data=(x_test, x_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2aa87721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: InputLayer, input shapes: [[None, 784]], output shape: [None, 784]\n",
      "Layer name: encoder_dense, layer type: Dense, input shapes: [[None, 784]], output shape: [None, 32]\n",
      "Layer name: decoder_dense, layer type: Dense, input shapes: [[None, 32]], output shape: [None, 784]\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: InputLayer, input shapes: [[None, 784]], output shape: [None, 784]\n",
      "Layer name: encoder_dense, layer type: Dense, input shapes: [[None, 784]], output shape: [None, 32]\n",
      "Layer name: decoder_dense, layer type: Dense, input shapes: [[None, 32]], output shape: [None, 784]\n",
      "Creating HLS model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<hls4ml.model.graph.ModelGraph at 0x7fd31e6a8c40>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create default hls4ml config from the Keras model\n",
    "config = hls4ml.utils.config_from_keras_model(\n",
    "    autoencoder,\n",
    "    granularity='model'   # start simple; can switch to 'name' later for per-layer tuning\n",
    ")\n",
    "# Increase precision so tiny values donâ€™t round to 0\n",
    "config['Model']['Precision'] = 'ap_fixed<32,6>'\n",
    "\n",
    "config\n",
    "\n",
    "output_dir = 'tiny_ae_hls_keras'\n",
    "\n",
    "hls_model = hls4ml.converters.convert_from_keras_model(\n",
    "    autoencoder,\n",
    "    hls_config=config,\n",
    "    output_dir=output_dir,\n",
    "    part='xc7z020clg400-1',   # PYNQ-Z2 FPGA\n",
    "    backend='Vivado'          # or 'Vitis', depending on your tools\n",
    ")\n",
    "\n",
    "hls_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65cd7cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: InputLayer, input shapes: [[None, 784]], output shape: [None, 784]\n",
      "Layer name: encoder_dense, layer type: Dense, input shapes: [[None, 784]], output shape: [None, 32]\n",
      "Layer name: decoder_dense, layer type: Dense, input shapes: [[None, 32]], output shape: [None, 784]\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: InputLayer, input shapes: [[None, 784]], output shape: [None, 784]\n",
      "Layer name: encoder_dense, layer type: Dense, input shapes: [[None, 784]], output shape: [None, 32]\n",
      "Layer name: decoder_dense, layer type: Dense, input shapes: [[None, 32]], output shape: [None, 784]\n",
      "Creating HLS model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<hls4ml.model.graph.ModelGraph at 0x7fd31d05fd90>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create hls4ml config (model-level)\n",
    "config = hls4ml.utils.config_from_keras_model(\n",
    "    autoencoder,\n",
    "    granularity='model'\n",
    ")\n",
    "\n",
    "# For now: use float precision so we can debug accuracy easily\n",
    "config['Model']['Precision'] = 'ap_fixed<16,6>'\n",
    "\n",
    "config\n",
    "\n",
    "# Use a NEW output directory to avoid reusing the old project\n",
    "output_dir = 'tiny_ae_hls_keras_float'\n",
    "\n",
    "hls_model = hls4ml.converters.convert_from_keras_model(\n",
    "    autoencoder,\n",
    "    hls_config=config,\n",
    "    output_dir=output_dir,\n",
    "    part='xc7z020clg400-1',   # PYNQ-Z2 FPGA\n",
    "    backend='Vivado'\n",
    ")\n",
    "\n",
    "hls_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01397c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing HLS project\n",
      "Done\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "Keras output (first sample, first 10 values):\n",
      "[4.6985159e-07 5.8301243e-06 1.2115156e-06 3.8756561e-06 5.1274365e-06\n",
      " 8.3250239e-07 1.5908506e-06 3.4158427e-06 4.9885289e-06 1.0767915e-06]\n",
      "\n",
      "HLS output (first sample, first 10 values):\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "\n",
      "****** Vitis HLS - High-Level Synthesis from C, C++ and OpenCL v2023.1 (64-bit)\n",
      "  **** SW Build 3854077 on May  4 2023\n",
      "  **** IP Build 3864474 on Sun May  7 20:36:21 MDT 2023\n",
      "  **** SharedData Build 3865790 on Sun May 07 13:33:03 MDT 2023\n",
      "    ** Copyright 1986-2022 Xilinx, Inc. All Rights Reserved.\n",
      "    ** Copyright 2022-2023 Advanced Micro Devices, Inc. All Rights Reserved.\n",
      "\n",
      "source /tools/Xilinx/Vitis_HLS/2023.1/scripts/vitis_hls/hls.tcl -notrace\n",
      "INFO: [HLS 200-10] Running '/tools/Xilinx/Vitis_HLS/2023.1/bin/unwrapped/lnx64.o/vitis_hls'\n",
      "INFO: [HLS 200-10] For user 'ubuntu2004' on host 'ubuntu2004-virtual-machine' (Linux_x86_64 version 5.15.0-139-generic) on Sun Dec 07 19:37:55 CST 2025\n",
      "INFO: [HLS 200-10] On os Ubuntu 20.04.6 LTS\n",
      "INFO: [HLS 200-10] In directory '/home/ubuntu2004/527 final/tiny_ae_hls_keras_float'\n",
      "Sourcing Tcl script 'build_prj.tcl'\n",
      "INFO: [HLS 200-1510] Running: open_project myproject_prj \n",
      "ERROR: [HLS 200-70] Project/solution path '/home/ubuntu2004/527 final/tiny_ae_hls_keras_float/myproject_prj' contains illegal character ' '.\n",
      "command 'ap_source' returned error code\n",
      "    while executing\n",
      "\"source build_prj.tcl\"\n",
      "    (\"uplevel\" body line 1)\n",
      "    invoked from within\n",
      "\"uplevel \\#0 [list source $arg] \"\n",
      "\n",
      "INFO: [HLS 200-112] Total CPU user time: 0.42 seconds. Total CPU system time: 0.16 seconds. Total elapsed time: 0.95 seconds; peak allocated memory: 98.996 MB.\n",
      "INFO: [Common 17-206] Exiting vitis_hls at Sun Dec  7 19:37:55 2025...\n",
      "Project myproject_prj does not exist. Rerun \"hls4ml build -p tiny_ae_hls_keras_float\".\n"
     ]
    }
   ],
   "source": [
    "# 1) Compile HLS model (C-simulation)\n",
    "hls_model.compile()\n",
    "\n",
    "# 2) Compare Keras vs HLS on some random inputs\n",
    "X_test_small = x_test[:10]  # 10 samples\n",
    "\n",
    "y_keras = autoencoder.predict(X_test_small)\n",
    "y_hls   = hls_model.predict(X_test_small)\n",
    "\n",
    "print(\"Keras output (first sample, first 10 values):\")\n",
    "print(y_keras[0][:10])\n",
    "\n",
    "print(\"\\nHLS output (first sample, first 10 values):\")\n",
    "print(y_hls[0][:10])\n",
    "\n",
    "# Need to run on computer install Vivado/Vitis\n",
    "# # 3) Build the HLS project - synthesis + RTL\n",
    "hls_model.build(csim=False, synth=True, vsynth=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0e5dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 6ms/step\n",
      "Keras Autoencoder\n",
      "MSE: 0.010832703\n",
      "MAE: 0.037136964\n",
      "PSNR: 19.652632025838535\n",
      "SSIM: 0.8369306381560924\n"
     ]
    }
   ],
   "source": [
    "from skimage.metrics import structural_similarity as ssim\n",
    "import numpy as np\n",
    "\n",
    "X_eval = x_test[:1000]\n",
    "y_pred = autoencoder.predict(X_eval)\n",
    "\n",
    "# MSE\n",
    "mse = np.mean((X_eval - y_pred)**2)\n",
    "\n",
    "# MAE\n",
    "mae = np.mean(np.abs(X_eval - y_pred))\n",
    "\n",
    "# PSNR\n",
    "max_pixel = 1.0\n",
    "psnr = 20 * np.log10(max_pixel / np.sqrt(mse))\n",
    "\n",
    "# SSIM (compute on 1 sample reshaped to 28x28)\n",
    "sample_ssim = ssim(\n",
    "    X_eval[0].reshape(28,28), \n",
    "    y_pred[0].reshape(28,28), \n",
    "    data_range=1.0\n",
    ")\n",
    "\n",
    "print(\"Keras Autoencoder\")\n",
    "print(\"MSE:\", mse)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"PSNR:\", psnr)\n",
    "print(\"SSIM:\", sample_ssim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dae72e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HLS Autoencoder\n",
      "MSE: 0.013141696\n",
      "MAE: 0.03941136\n",
      "PSNR: 18.81348551255607\n",
      "SSIM: 0.8418079526202122\n"
     ]
    }
   ],
   "source": [
    "from skimage.metrics import structural_similarity as ssim\n",
    "import numpy as np\n",
    "\n",
    "X_eval = x_test[:1000]\n",
    "y_pred = hls_model.predict(X_eval)\n",
    "\n",
    "# MSE\n",
    "mse = np.mean((X_eval - y_pred)**2)\n",
    "\n",
    "# MAE\n",
    "mae = np.mean(np.abs(X_eval - y_pred))\n",
    "\n",
    "# PSNR\n",
    "max_pixel = 1.0\n",
    "psnr = 20 * np.log10(max_pixel / np.sqrt(mse))\n",
    "\n",
    "# SSIM (compute on 1 sample reshaped to 28x28)\n",
    "sample_ssim = ssim(\n",
    "    X_eval[0].reshape(28,28), \n",
    "    y_pred[0].reshape(28,28), \n",
    "    data_range=1.0\n",
    ")\n",
    "\n",
    "print(\"HLS Autoencoder\")\n",
    "print(\"MSE:\", mse)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"PSNR:\", psnr)\n",
    "print(\"SSIM:\", sample_ssim)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
